{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Normalize\") \\\n",
    "    .config(\"spark.local.dir\",\"C:\\\\Users\\\\justy\\\\Documents\\\\USC\\\\Fall 2018\\\\INF 553\\\\Project\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#df = spark.read.json('C:/Users/justy/Documents/GitHub/inf553-adjusted-ratings/dataset-extraction/thousand.json', multiLine=True)\n",
    "df = spark.read.json('C:/Users/justy/Documents/GitHub/inf553-adjusted-ratings/tenthousand.json', multiLine=True)\n",
    "\n",
    "\n",
    "print(\"Number of reviews: %d\" % df.count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Reviews: 9999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# normalized stars (first 1000 reviews)\n",
    "dfSent = spark.read.json(\"C:/Users/justy/Documents/GitHub/inf553-adjusted-ratings/2030google-results.json\", multiLine=True)\n",
    "\n",
    "#dfSent = spark.read.json('C:\\\\Users\\\\justy\\\\Documents\\\\USC\\\\Fall 2018\\\\INF 553\\\\Project\\\\converged.json', multiLine=True)\n",
    "print(\"Num Reviews: %d\" % dfSent.count())\n",
    "\n",
    "def normalizeValue(minVal, maxVal, val):\n",
    "    rangeVal = maxVal - minVal\n",
    "    return (val - minVal) / rangeVal\n",
    "\n",
    "def normalizeValueDist(star, tscore):\n",
    "    return 3 + (star-3)/1.5 + tscore/3\n",
    "\n",
    "def buckets(user, val):\n",
    "    if val == 1:\n",
    "        return (user, (1,0,0,0,0))\n",
    "    elif val == 2:\n",
    "        return (user, (0,1,0,0,0))\n",
    "    elif val == 3:\n",
    "        return (user, (0,0,1,0,0))\n",
    "    elif val == 4:\n",
    "        return (user, (0,0,0,1,0))\n",
    "    else:\n",
    "        return (user, (0,0,0,0,1))\n",
    "\n",
    "def modeNum(buckets):\n",
    "    count = 0\n",
    "    if buckets[0] > buckets[1]:\n",
    "        count += 1\n",
    "    if (buckets[1] > buckets[0]) & (buckets[1] > buckets[2]):\n",
    "        count += 1\n",
    "    if (buckets[2] > buckets[1]) & (buckets[2] > buckets[3]):\n",
    "        count += 1\n",
    "    if (buckets[3] > buckets[2]) & (buckets[3] > buckets[4]):\n",
    "        count += 1\n",
    "    if buckets[4] > buckets[3]:\n",
    "        count += 1\n",
    "    count = 1 if count == 0 else count\n",
    "    return count\n",
    "\n",
    "def SampleStDev(val, count):\n",
    "    if count == 1:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.sqrt(val/(count-1))\n",
    "\n",
    "def TScore(val, mean, std):\n",
    "    if std == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (val - mean)/std\n",
    "\n",
    "\n",
    "def getTScore(scoreMap, reviewId):\n",
    "    if reviewId in scoreMap:\n",
    "        return scoreMap[reviewId]\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def getAdjStars(sentStar, modes, reviews, mean, tscore, lowT, highT):\n",
    "    if modes == 1:\n",
    "        if reviews == 1:\n",
    "            return mean\n",
    "        else:\n",
    "            return tscore + 3\n",
    "    elif modes == 2:\n",
    "        if sentStar < 3:\n",
    "            return lowT / 2 + 2.5\n",
    "        else:\n",
    "            return highT / 2 + 3\n",
    "    return tscore + 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Get expanded star ratings using sentiment, summary stats *****\n",
      "Execution time: 12.532726\n",
      "\n",
      "***** Get number of modes per user *****\n",
      "Execution time: 2.959246\n",
      "\n",
      "***** Get T-scores for full dist, low dist, and high dist *****\n",
      "Execution time: 32.685280\n",
      "\n",
      "***** Get final normalized star rating *****\n",
      "Execution time: 6.302089\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "t0 = time.clock()\n",
    "rddStart = dfSent.rdd\n",
    "rddSent = rddStart.map(lambda row: (row['user_id'], row['stars'], row['sentiment-google'], row['review_id']))\n",
    "\n",
    "''' ***** Get expanded star ratings using sentiment, summary stats ***** '''\n",
    "print('***** Get expanded star ratings using sentiment, summary stats *****')\n",
    "\n",
    "# (star: mean sentiment)\n",
    "meanMap = rddSent.map(lambda x: (x[1], (x[2], 1))) \\\n",
    "    .reduceByKey(lambda sumCnt1, sumCnt2: (sumCnt1[0]+sumCnt2[0], sumCnt1[1]+sumCnt2[1])) \\\n",
    "    .map(lambda sumCnt: (sumCnt[0], sumCnt[1][0]/sumCnt[1][1])).collectAsMap() \n",
    "\n",
    "# (star: std dev sentiment)\n",
    "stdMap = rddSent.map(lambda x: (x[1], ((x[2] - meanMap[x[1]])**2,1) ) ) \\\n",
    "    .reduceByKey(lambda sumCnt1, sumCnt2: (sumCnt1[0]+sumCnt2[0], sumCnt1[1]+sumCnt2[1])) \\\n",
    "    .map(lambda sumCnt: (sumCnt[0], SampleStDev(sumCnt[1][0],sumCnt[1][1]) )).collectAsMap()\n",
    "\n",
    "# (review_id: t-score sentiment)\n",
    "tscoreStar = rddSent.map(lambda x: (x[3], TScore(x[2],meanMap[x[1]],stdMap[x[1]]) ) ).collectAsMap()\n",
    "\n",
    "#rddRanges = rddSent.map(lambda row: (row[1], (row[2], row[2]))).reduceByKey(lambda x1, x2: (min(x1[0], x2[0]), max(x1[1], x2[1])))\n",
    "#rangeMap = rddRanges.sortByKey().collectAsMap()\n",
    "\n",
    "# (user_id, expanded star using sentiment, review_id, stars)\n",
    "rddSentStars = rddSent.map(lambda row: (row[0], normalizeValueDist(row[1], tscoreStar[row[3]]), \\\n",
    "                                        row[3], row[1]))\n",
    "\n",
    "# (user_id, expanded star using sentiment, review_id, stars)\n",
    "#rddSentStars = rddSent.map(lambda row: (row[0], row[1]-0.5+normalizeValue(rangeMap[row[1]][0],rangeMap[row[1]][1],row[2]), \\\n",
    "#                                        row[3], row[1]))\n",
    "\n",
    "# review count, mean by user_id\n",
    "countsMap = rddSentStars.map(lambda x: (x[0], (x[1], 1))) \\\n",
    "    .reduceByKey(lambda cnt1, cnt2: (cnt1[0]+cnt2[0], cnt1[1]+cnt2[1]) ) \\\n",
    "    .map(lambda cntAvg: (cntAvg[0], (cntAvg[1][1], cntAvg[1][0]/cntAvg[1][1])) ).collectAsMap()\n",
    "    \n",
    "elapsed = time.clock() - t0\n",
    "print(\"Execution time: %f\\n\" % elapsed)\n",
    "\n",
    "''' ***** Get number of modes per user ***** '''\n",
    "print('***** Get number of modes per user *****')\n",
    "t0 = time.clock()\n",
    "\n",
    "# (user_id, bucket counts tuple)\n",
    "rddBuckets = rddSent.map(lambda row: buckets(row[0], row[1])) \\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1], x[2]+y[2], x[3]+y[3], x[4]+y[4]))\n",
    "\n",
    "# (user_id: number of modes)\n",
    "modesMap = rddBuckets.map(lambda x: (x[0], modeNum(x[1]))).collectAsMap()\n",
    "elapsed = time.clock() - t0\n",
    "print(\"Execution time: %f\\n\" % elapsed)\n",
    "\n",
    "''' ***** Get T-scores for full dist, low dist, and high dist ***** '''\n",
    "print('***** Get T-scores for full dist, low dist, and high dist *****')\n",
    "t0 = time.clock()\n",
    "\n",
    "rddFull = rddSentStars.flatMap(lambda x: [(x[0], x[1], x[2])] )\n",
    "rddHigh = rddSentStars.flatMap(lambda x: [(x[0], x[1], x[2])] if x[1] >= 3 else [] )\n",
    "rddLow = rddSentStars.flatMap(lambda x: [(x[0], x[1], x[2])] if x[1] < 3 else [] )\n",
    "\n",
    "tscoreList = [rddFull, rddLow, rddHigh]\n",
    "\n",
    "\n",
    "lowHighSum = []\n",
    "for rdd in tscoreList:\n",
    "\n",
    "    # (user_id: mean)\n",
    "    meanMap = rdd.map(lambda x: (x[0], (x[1], 1))) \\\n",
    "        .reduceByKey(lambda sumCnt1, sumCnt2: (sumCnt1[0]+sumCnt2[0], sumCnt1[1]+sumCnt2[1])) \\\n",
    "        .map(lambda sumCnt: (sumCnt[0], sumCnt[1][0]/sumCnt[1][1])).collectAsMap() \n",
    "\n",
    "    # (user_id, std dev)\n",
    "    stdMap = rdd.map(lambda x: (x[0], ((x[1] - meanMap[x[0]])**2,1) ) ) \\\n",
    "        .reduceByKey(lambda sumCnt1, sumCnt2: (sumCnt1[0]+sumCnt2[0], sumCnt1[1]+sumCnt2[1])) \\\n",
    "        .map(lambda sumCnt: (sumCnt[0], SampleStDev(sumCnt[1][0],sumCnt[1][1]) )).collectAsMap()\n",
    "    \n",
    "    # (review_id, t-score)\n",
    "    tscoreRdd = rdd.map(lambda x: (x[2], TScore(x[1],meanMap[x[0]],stdMap[x[0]]) ) ).collectAsMap()\n",
    "    lowHighSum.append(tscoreRdd)\n",
    "    \n",
    "elapsed = time.clock() - t0\n",
    "print(\"Execution time: %f\\n\" % elapsed)\n",
    "    \n",
    "''' ***** Get final normalized star rating ***** '''\n",
    "print('***** Get final normalized star rating *****')\n",
    "t0 = time.clock()\n",
    "\n",
    "fullMap = lowHighSum[0]\n",
    "lowMap  = lowHighSum[1]\n",
    "highMap = lowHighSum[2]\n",
    "\n",
    "# (review_id, sentiment stars, # of modes, # of reviews, user mean, full t-score, low t-score, high t-score, \\\n",
    "#              user_id, stars)\n",
    "rddAll = rddSentStars.map(lambda x: (x[2], x[1], modesMap[x[0]], countsMap[x[0]][0], \\\n",
    "                                     countsMap[x[0]][1], getTScore(fullMap, x[2]), \\\n",
    "                                     getTScore(lowMap, x[2]), getTScore(highMap, x[2]), \\\n",
    "                                     x[0], x[3]) )\n",
    "\n",
    "# map of (review_id : business_id)\n",
    "businessMap = rddStart.map(lambda row: (row['review_id'], row['business_id'])).collectAsMap()\n",
    "\n",
    "def getBusiness(bizMap, review_id):\n",
    "    return (review_id, bizMap[review_id])\n",
    "\n",
    "rddAdjStars = rddAll.map(lambda x: (getAdjStars(x[1], x[2], x[3], x[4], x[5], x[6], x[7]), \\\n",
    "                          businessMap[x[0]], x[8], x[9])).collect()\n",
    "\n",
    "elapsed = time.clock() - t0\n",
    "print(\"Execution time: %f\\n\" % elapsed)    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# (user_id, expanded star using sentiment, review_id, stars)\n",
    "Qss = pd.DataFrame(rddAdjStars, columns = ['Adj_Stars', 'stars', 'sentiment'])\n",
    "\n",
    "lowStar = 0.5\n",
    "highStar = 1.5\n",
    "\n",
    "for i in range(5):\n",
    "    mid = (lowStar + highStar) / 2\n",
    "    plt.hist(Qss[(Qss['Adj_Stars']>lowStar) & (Qss['Adj_Stars']<highStar)]['sentiment'], \\\n",
    "             bins=[-1.05,-.95,-.85,-.75,-.65,-.55,-.45,-.35,-.25,-.15,-.05,.05,.15,.25,.35, \\\n",
    "                  .45,.55,.65,.75,.85,.95,1.05])\n",
    "    plt.title(\"Adj Stars %d Distribution\" % highStar)\n",
    "    plt.show()\n",
    "    lowStar += 1\n",
    "    highStar += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "4 columns passed, passed data had 3 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-315-a0687d1481b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mQAll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrddAdjStars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Adj_Stars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'business_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQAll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'orange'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sentiment Stars Distribution\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Star Rating\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5615\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5616\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m-> 5617\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m   5618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5619\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5694\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5695\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m-> 5696\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m   5697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5753\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5754\u001b[0m             raise AssertionError('%d columns passed, passed data had %s '\n\u001b[1;32m-> 5755\u001b[1;33m                                  'columns' % (len(columns), len(content)))\n\u001b[0m\u001b[0;32m   5756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5757\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 4 columns passed, passed data had 3 columns"
     ]
    }
   ],
   "source": [
    "QAll = pd.DataFrame(rddAdjStars, columns=['Adj_Stars', 'business_id', 'user_id', 'stars'])\n",
    "\n",
    "plt.hist(QAll['stars'], bins=[0.5,1.5,2.5,3.5,4.5,5.5], color='orange')\n",
    "plt.title(\"Sentiment Stars Distribution\")\n",
    "plt.xlabel(\"Star Rating\")\n",
    "plt.ylabel(\"Review Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(QAll['Adj_Stars'], bins=[0.25,0.75,1.25,1.75,2.25,2.75,3.25,3.75,4.25,4.75,5.25,5.75], color='green')\n",
    "plt.title(\"Normalized Stars Distribution\")\n",
    "plt.xlabel(\"Normalized Star Rating\")\n",
    "plt.ylabel(\"Review Count\")\n",
    "plt.show()\n",
    "\n",
    "std1 = len(QAll[(QAll['Adj_Stars'] < 4) & (QAll['Adj_Stars'] > 2)])/len(QAll)\n",
    "print(\"Within 1 StD: %f\" % std1)\n",
    "std2 = len(QAll[(QAll['Adj_Stars'] < 5) & (QAll['Adj_Stars'] > 1)])/len(QAll)\n",
    "print(\"Within 2 StD: %f\" % std2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output results to json file\n",
    "json = QAll.to_json(\"user_normalizedSentStars_10000.json\", orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
